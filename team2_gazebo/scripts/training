#!/usr/bin/env python

# Training the reinforcement learning model
# Author: Yan-Song Chen, Columbia University 2018
import rospy
from utils import MoveBaseClient, FollowTrajectoryClient, GazeboClient,\
                  PointHeadClient, GripperClient, GraspingClient, RL
from gazebo_msgs.msg import ModelStates, ModelState
from geometry_msgs.msg import Quaternion, Pose, Twist, Point
from moveit_python.geometry import rotate_pose_msg_by_euler_angles as rotate
from numpy import pi

if __name__ == "__main__":
  # Create a node
  rospy.init_node("training")

  # Make sure sim time is working
  while not rospy.Time.now():
      pass

  # Setup clients
  torso_action = FollowTrajectoryClient("torso_controller",\
                                        ["torso_lift_joint"])
  gripper_action = GripperClient()
  head_action = PointHeadClient()
  grasping_client = GraspingClient()
  gazebo_client = GazeboClient()
  rl_model = RL()

  rospy.loginfo("Lifting torso...")
  torso_action.move_to([0.4,])

  rospy.loginfo("Looking at table")
  head_action.look_at(0.8, 0.0, 0.0, "base_link")

  ## Gripper pose downward, for future grasp planning
  # downward = Quaternion(0.0,1.57,0.0,1.57)

  rospy.loginfo("Begin learning...")
  while not rospy.is_shutdown():
    rl_action = rl_model.action()
    new_state = ModelState()
    new_state.model_name =rl_action['name']
    new_state.pose = Pose( Point(rl_action['x'],rl_action['y'], 0.8),\
                           Quaternion(0,0,0,0))
    new_state.pose = rotate(new_state.pose, 0, 0, rl_action['theta'])
    gazebo_client.set_pose(new_state)

    # Wait for the physics to stabilize
    rospy.sleep(0.2)

  grasping_client.cancel()
